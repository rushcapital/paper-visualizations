{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "def find_coordinates():\n",
    "    data = pd.read_csv('../surveys/Three Forks CD/2010 DMR Three Forks Assessment CD/LogsUsedAllWells.DAT', \n",
    "            sep=\"\\s+\", \n",
    "            skiprows=1, \n",
    "            usecols=[i for i in range(8)], \n",
    "            names = ['API','DEPTH','POROSITY','RT','RW','SW','So', 'TEMP(F)'])\n",
    "    \n",
    "    # get all the unique api no's, then go to drillinginfo and extract the coordinates\n",
    "    api_nos = data['API'].unique()\n",
    "    \n",
    "    # read in and create a dictionary of surface coordinates per well for later reference\n",
    "    envernus = pd.read_csv('../datasets/three forks wells.CSV')\n",
    "    envernus = envernus.rename(columns={\n",
    "        'Surface Hole Latitude (WGS84)': 'surface_latitude',\n",
    "        'Surface Hole Longitude (WGS84)': 'surface_longitude',\n",
    "        'True Vertical Depth': 'TVD'\n",
    "    })  \n",
    "\n",
    "    coordinate_dict = {\n",
    "        row['API14']: {\n",
    "            'latitude':row['surface_latitude'],\n",
    "            'longitude':row['surface_longitude'],\n",
    "            'tvd':row['TVD']\n",
    "        }\n",
    "        for _, row in envernus.iterrows()\n",
    "    }\n",
    "\n",
    "    # once created, write to housekeeping directory for later use.    \n",
    "    with open('../housekeeping/three_forks_coordinates.pkl', 'wb') as handle:\n",
    "        pickle.dump(coordinate_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "find_coordinates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "\n",
    "def generate_LAS_file_list(directory):\n",
    "    return glob.glob(directory)\n",
    "\n",
    "def pickle_LAS(file):\n",
    "    with open(file, 'r') as f:\n",
    "        lines = list(filter(None,[line.strip().split() for line in f.read().splitlines() if line]))\n",
    "    \n",
    "    # find what we care about: the apino, and the data delimiter, ~A.\n",
    "    for idx, line in enumerate(lines):\n",
    "\n",
    "        if 'API' in line[0]:\n",
    "            api_no = line[1]\n",
    "            \n",
    "        # this will always be found after we know the api_no, so break.\n",
    "        if '~A' in line[0]:\n",
    "            data_start = idx+1\n",
    "            break\n",
    "\n",
    "    data = pd.DataFrame(lines[data_start:],\n",
    "                        columns = ['DEPTH', 'DENSITY_POROSITY', 'RT','RW', 'SW','TEMP(F)'])\n",
    "    \n",
    "    # once created, write to housekeeping directory for later use.    \n",
    "    with open(f'../datasets/three forks/{api_no}.pkl', 'wb') as handle:\n",
    "        pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "LAS_files = generate_LAS_file_list('../surveys/Three Forks CD/2010 DMR Three Forks Assessment CD/LAS Files/*')\n",
    "\n",
    "for file in LAS_files:\n",
    "    pickle_LAS(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_3fork_logs(file):\n",
    "    with open(file, 'rb') as handle:\n",
    "        data = pickle.load(handle).astype(float)\n",
    "    \n",
    "    # i know there will always be the same count of curves just because \n",
    "    # thats the way the data's structured, but just want some flexibility later.\n",
    "    data = data.set_index(data.columns[0])\n",
    "    curve_count = len(data.columns)\n",
    "    \n",
    "    # find the min, max of first column to use gradient-area fill plotting.\n",
    "    def area_fill(data, col, fig, count):\n",
    "\n",
    "        ref = data[col]\n",
    "        _min, _max = ref.min(), ref.max() \n",
    "        span = abs(_max - _min)\n",
    "        cmap = plt.get_cmap('viridis')\n",
    "        color_index = np.arange(_min, _max, span/100)\n",
    "\n",
    "        axs[count].plot(ref, data.index, color='black')\n",
    "\n",
    "        # given the density-porosity, visualize the \n",
    "        for index in sorted(color_index):\n",
    "            index_value = (index - _min) / span\n",
    "            color = cmap(index_value)\n",
    "        \n",
    "            axs[count].fill_betweenx(data.index, _max, ref, \n",
    "                            where=ref>=index,\n",
    "                            color=color)\n",
    "\n",
    "            axs[count].set(xlabel = col)\n",
    "            axs[count].xaxis.set_label_position('top')\n",
    "            axs[count].tick_params(axis='x', rotation=315)\n",
    "\n",
    "    fig, axs = plt.subplots(1,3,figsize=(24,24),\n",
    "                            sharey=True)\n",
    "\n",
    "    # only need to invert one y-axis since they're shared.\n",
    "    axs[0].invert_yaxis()\n",
    "    \n",
    "    count = 0\n",
    "    for col in ['DENSITY_POROSITY', 'RT','SW']:\n",
    "         area_fill(data, col, axs, count)\n",
    "         count+=1        \n",
    "    \n",
    "plot_3fork_logs('../datasets/three forks/33007009970000.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import interactive\n",
    "\n",
    "interactive = True\n",
    "%matplotlib qt\n",
    "\n",
    "def verify_3fork_data():\n",
    "    \n",
    "    # first, read in our dictionary with longitudes and latitudes\n",
    "    with open('../housekeeping/three_forks_coordinates.pkl', 'rb') as handle:\n",
    "        coordinates = pickle.load(handle)\n",
    "    \n",
    "    # create sets out of the two lists, ensure the types are same, find intersection\n",
    "    # between sets to get the api14's we need.\n",
    "    _t = set(coordinates.keys())\n",
    "    directories = glob.glob('../datasets/three forks/*')\n",
    "    _d = set([int(d.split('\\\\')[1].split('.')[0]) for d in directories])\n",
    "    \n",
    "    # valid.\n",
    "    apis = list(_t.intersection(_d))\n",
    "\n",
    "    coordinates = {k:v for k,v in coordinates.items() if k in apis}\n",
    "    \n",
    "    return_coordinates = coordinates.copy()\n",
    "    for key in coordinates:\n",
    "        with open(f'../datasets/three forks/{key}.pkl', 'rb') as handle:\n",
    "            data = pickle.load(handle)\n",
    "            return_coordinates[key]['max_depth'] = data['DEPTH'].iloc[-1]\n",
    "            return_coordinates[key]['min_depth'] = data['DEPTH'].iloc[0]\n",
    "            \n",
    "    # once created, write to housekeeping directory for later use.    \n",
    "    with open('../housekeeping/three_forks_coordinates_depth.pkl', 'wb') as handle:\n",
    "        pickle.dump(return_coordinates, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    return apis\n",
    "\n",
    "api14_nos = verify_3fork_data()\n",
    "\n",
    "def generate_3forks_surface(api_nos):\n",
    "    \n",
    "    # first, read in our dictionary with longitudes and latitudes\n",
    "    with open('../housekeeping/three_forks_coordinates_depth.pkl', 'rb') as handle:\n",
    "        _coordinates = pickle.load(handle)\n",
    "\n",
    "    dataframe = pd.DataFrame.from_dict(_coordinates, orient='index').astype(float)\n",
    "    \n",
    "    X, Y, Z_top, Z_bot = dataframe['latitude'], dataframe['longitude'], dataframe['min_depth'], dataframe['max_depth']\n",
    "\n",
    "    # to Add a color bar which maps values to colors.\n",
    "    fig = plt.figure(figsize=(20,12))\n",
    "    ax = fig.gca(projection='3d')\n",
    "    surf=ax.plot_trisurf(Y, X, Z_top, cmap=plt.cm.viridis,\n",
    "                        edgecolor='none', linewidth=0, antialiased=False)\n",
    "    cbar = fig.colorbar( surf, shrink=0.5, aspect=5, )\n",
    "    cbar.set_label('Three Forks Top (ft)')\n",
    "    ax.set_xlabel('Bottom Hole Latitude (WGS84)')\n",
    "    ax.set_ylabel('Bottom Hole Longitude (WGS84)')\n",
    "    ax.set_zlabel('Three Forks Top (ft)')\n",
    "    ax.invert_zaxis()\n",
    "\n",
    "    # to Add a color bar which maps values to colors.\n",
    "    fig = plt.figure(figsize=(20,12))\n",
    "    ax = fig.gca(projection='3d')\n",
    "    surf=ax.plot_trisurf(Y, X, Z_bot, cmap=plt.cm.viridis,\n",
    "                        edgecolor='none', linewidth=0, antialiased=False)\n",
    "    cbar = fig.colorbar( surf, shrink=0.5, aspect=5, )\n",
    "    cbar.set_label('Three Forks Top (ft)')\n",
    "    ax.set_xlabel('Bottom Hole Latitude (WGS84)')\n",
    "    ax.set_ylabel('Bottom Hole Longitude (WGS84)')\n",
    "    ax.set_zlabel('Three Forks Top (ft)')\n",
    "    ax.invert_zaxis()\n",
    "\n",
    "    plt.show()    \n",
    "\n",
    "generate_3forks_surface(api14_nos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['33007011850000', '33007014220000', '33007014300000', '33007014390000', '33007014480000', '33007014590000', '33007014690000', '33007015020000', '33007015070000', '33007015130000', '33007015420000', '33007015540000', '33007015630000', '33007015750000', '33007015800000', '33013013830000', '33013014020000', '33013014140000', '33013014310000', '33013014340000', '33023004510000', '33023004550000', '33023004590000', '33023004620000', '33023004630000', '33023004660000', '33023004800000', '33023004890000', '33023005040000', '33025005890000', '33025005970000', '33025006690000', '33025007160000', '33025007280000', '33033002390000', '33053023570000', '33053025320000', '33053025390000', '33053025500000', '33053025520000', '33053025890000', '33053026470000', '33053026690000', '33053026720000', '33053026840000', '33053027040000', '33053027200000', '33053027410000', '33053027480000', '33053027570000', '33053027600000', '33053027690000', '33053027940000', '33053028060000', '33053028080000', '33053028530000', '33053028580000', '33053028940000', '33057000350000', '33061004900000', '33061004940000', '33061004950000', '33061004980000', '33061005030000', '33061005210000', '33061005540000', '33061005770000', '33061005780000', '33061005810000', '33061005870000', '33061005900000', '33061005910000', '33061005960000', '33061006300000', '33061006410000', '33061006530000', '33061006600000', '33061006660000', '33061006800000', '33061006850000', '33061007220000', '33061007490000', '33089005690000', '33105014890000', '33105015270000', '33105015510000', '33105015570000', '33105015730000', '33105015980000', '33105016130000', '33105016360000', '33105016930000', '33105016930100']\n"
     ]
    }
   ],
   "source": [
    "# create folders for all these damn trajectories. im downloading them by hand bro..\n",
    "import os\n",
    "\n",
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)\n",
    "\n",
    "with open('../housekeeping/3fork trajectories.txt') as f:\n",
    "    lines = f.read().splitlines()\n",
    "    print(lines)\n",
    "# for api in lines:\n",
    "#     createFolder(f'../datasets/three forks/trajectories/{api}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bbc12c53a9d6275dff530b7ee635959a53250dbe432a258f19f50f2262d6d3ce"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
